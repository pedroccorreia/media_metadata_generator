project_id = "sample-project"

input_bucket_names = [
  "sample-project-input"
]

# you can override the models that each worker uses
summaries_generator_llm_model = "gemini-2.5-pro"
transcription_generator_llm_model = "chirp"
previews_generator_llm_model = "gemini-2.5-flash"


# Once you deploy your infrastructure, update the artifact registry by running services/artifacts_build
# Uncomment the lines below and run terraform to update to these images
# batch_processor_image      = "us-central1-docker.pkg.dev/sample-project/media-pipeline-images/batch_processor_dispatcher:latest"
# summaries_generator_image  = "us-central1-docker.pkg.dev/sample-project/media-pipeline-images/summaries_generator:latest"
# transcription_generator_image = "us-central1-docker.pkg.dev/sample-project/media-pipeline-images/transcription_generator:latest"
# previews_generator_image   = "us-central1-docker.pkg.dev/sample-project/media-pipeline-images/previews_generator:latest"


# Once you have your Vertex AI Search add these variable to point to the right engine: 
vais_location      = "global"
vais_collection_id = "default_collection"
vais_engine_id     = "vais_engine_id"